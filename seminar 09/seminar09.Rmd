## STAT 540 Seminar 9: Cluster Analysis and PCA
### Hao Chen
__2014-03-21__

* <dim id="1a">[Load data and packages](#1b)
* <dim id="2a">[Sample Clustering](#2b)
   * <dim id="2a1">[Hierarchical clustering for `photoRec` data](#2b1)
   * <dim id="2a2">[Partitioning methods for `photoRec` data](#2b2) 
   * <dim id="2a3">[Exercise](#2b3) 
* <dim id="3a">[Gene clustering](#3b)
* <dim id="4a">[Statistical measures to evaluate clusters](#4b)
* <dim id="5a">[PCA (principal components analysis)](#5b)

> The R markdown file can be found on my [Github](https://github.com/nelsonch/stat540-2014-chen-hao/blob/master/seminar%2009/seminar09.Rmd).

```{r include = FALSE}
opts_chunk$set(tidy = F, warning=F, comment=NA, prompt=T)
```

### <dim id="1b">[Load data and packages](#1a)
Load required packages.
```{r, message=FALSE}
library(RColorBrewer)
library(cluster)
library(pvclust)
library(xtable)
library(limma)
library(plyr)
library(lattice)
```

Load the `photoRec` data.
```{r}
prDat <- read.table("GSE4051_data.tsv", header = TRUE, row.names = 1)
str(prDat, max.level = 0)
prDes <- readRDS("GSE4051_design.rds")
str(prDes)
```

Rescale the rows
```{r}
sprDat <- t(scale(t(prDat)))
str(sprDat, max.level = 0, give.attr = FALSE)
round(data.frame(avgBefore = rowMeans(head(prDat)),
                 avgAfter = rowMeans(head(sprDat)),
                 varBefore = apply(head(prDat), 1, var),
                 varAfter = apply(head(sprDat), 1, var)), 2)
```
> The data for each row -- which is for one probeset -- now has mean 0 and variance 1.

### <dim id="2b">[Sample Clustering](#2a)
#### <dim id="2b1">[Hierarchical clustering for `photoRec` data](#2a1)
> For most expression data applications, we suggest you should standardize the data; use Euclidean as the "distance" (so it's just like Pearson correlation) and use "average linkage".

```{r}
# compute pairwise distances
pr.dis <- dist(t(sprDat), method = 'euclidean')

# create a new factor representing the interaction of gType and devStage
prDes$grp <- with(prDes, interaction(gType, devStage))
summary(prDes$grp)

# compute hierarchical clustering using different linkage types
pr.hc.s <- hclust(pr.dis, method = 'single')
pr.hc.c <- hclust(pr.dis, method = 'complete')
pr.hc.a <- hclust(pr.dis, method = 'average')
pr.hc.w <- hclust(pr.dis, method = 'ward')

# plot them
op <- par(mar = c(0,4,4,2), mfrow = c(2,2))

plot(pr.hc.s, labels = FALSE, main = "Single", xlab = "")
plot(pr.hc.c, labels = FALSE, main = "Complete", xlab = "")
plot(pr.hc.a, labels = FALSE, main = "Average", xlab = "")
plot(pr.hc.w, labels = FALSE, main = "Ward", xlab = "")
par(op)

# identify 10 clusters
op <- par(mar = c(1,4,4,1))
plot(pr.hc.w, labels = prDes$grp, cex = 0.6, main = "Ward showing 10 clusters")
rect.hclust(pr.hc.w, k = 10)
par(op)
```

```{r}
jGraysFun <- colorRampPalette(brewer.pal(n = 9, "Greys"))
gTypeCols <- brewer.pal(11, "RdGy")[c(4,7)]
heatmap(as.matrix(sprDat), Rowv = NA, col = jGraysFun(256),
        hclustfun = function(x) hclust(x, method = 'ward'),
        scale = "none", labCol = prDes$grp, labRow = NA, margins = c(8,1),
        ColSideColor = gTypeCols[unclass(prDes$gType)])
legend("topright", legend = levels(prDes$gType),
       col = gTypeCols, lty = 1, lwd = 5, cex = 0.5)
```

#### <dim id="2b2">[Partitioning methods for `photoRec` data](#2a2) 
#### K-means clustering
Do a clustering of samples using all genes (~30K)
```{r, results='asis'}
set.seed(31)
k <- 5
pr.km <- kmeans(t(sprDat), centers = k, nstart =  50)

#We can look at the within sum of squares of each cluster
pr.km$withinss

#We can look at the composition of each cluster
pr.kmTable <- data.frame(devStage = prDes$devStage, cluster = pr.km$cluster)
prTable  <-  xtable(with(pr.kmTable, table(devStage,cluster)),
                    caption='Number of samples from each develomental stage within each k-means cluster')
align(prTable) <- "lccccc"
print(prTable, type = 'html', caption.placement = 'top')
```

Repeat the analysis using a different seed and check if you get the same clusters.
```{r, results='asis'}
set.seed(100)
pr.km <- kmeans(t(sprDat), centers = k, nstart =  50)
pr.kmTable <- data.frame(devStage = prDes$devStage, cluster = pr.km$cluster)
prTable  <-  xtable(with(pr.kmTable, table(devStage,cluster)),
                    caption='set.seed(100)')
print(prTable, type = 'html', caption.placement = 'top')

set.seed(540)
pr.km <- kmeans(t(sprDat), centers = k, nstart =  50)
pr.kmTable <- data.frame(devStage = prDes$devStage, cluster = pr.km$cluster)
prTable  <-  xtable(with(pr.kmTable, table(devStage,cluster)),
                    caption='set.seed(540)')
print(prTable, type = 'html', caption.placement = 'top')
```
* I get the same clusters using different seeds.

#### PAM algorithm
```{r, results='asis'}
pr.pam <- pam(pr.dis, k = k)
pr.pamTable <- data.frame(devStage = prDes$devStage,
                          cluster = pr.pam$clustering)
pamTable  <-  xtable(with(pr.pamTable, table(devStage, cluster)),
                     caption='Number of samples from each develomental stage within each PAM cluster')
align(pamTable) <- "lccccc"
print(pamTable, type = 'html', caption.placement = 'top')
```

__The silhouette plot__: the average of all objects silhouette widths gives an indication of how well the clusters are defined.
```{r}
op <- par(mar = c(5,1,4,4))
plot(pr.pam, main = "Silhouette Plot for 5 clusters")
par(op)
```

#### <dim id="2b3">[Exercise](#2a3) 
__Exercise 1:__ draw a plot with number of clusters in the x-axis and the average silhouette widths in the y-axis. Use the information obtained to determine if 5 was the best choice for the number of clusters.
```{r}
pamf <- function(ncluster){
  pr.pam <- pam(pr.dis, k = ncluster)
  return(pr.pam$silinfo$avg.width)
}
n <- 2:20
avewid <- rep(NA, 19)
for (i in 1:19){
  avewid[i] <- pamf(i+1)
}
plot(avewid ~ n, type="b", xlab="Number of clusters", ylab="Average silhouette width")
```
* 2 is the best choice for the number of cluster.

__Exercise 2:__ For a common choice of k, compare the clustering across different methods, e.g. hierarchical (pruned to specific k, obviously), k-means, PAM. You will re-discover the "label switching problem" for yourself. How does that manifest itself? How concordant are the clusterings for different methods?
> k is chosen as 5.

```{r, results='asis'}
### Hierarchical clustering with Ward method
op <- par(mar = c(1,4,4,1))
plot(pr.hc.w, labels = prDes$sidNum, cex = 0.6, main = "Ward showing 10 clusters")
rect.hclust(pr.hc.w, k = 5)
par(op)
```

```{r, echo=FALSE, results='asis'}
### results
cluster <- data.frame(Hierarchical_sidNum = c("7,8,16,33,34 (5) ", 
                                              "1,4,10,25,30,31,35 (7)",
                                              "3,5,12,14,24,26,27,28 (8)", 
                                              "2,11,13,15,19,37,38,39 (8)",
                                              "6,9,17,18,20,21,22,23,29,32,36 (11)"),
                      kmeans_sidNum = c("5,7,8,16,26,27,28,33,34 (9)",
                                        "1,3,4,10,14,24,25,30,31,35 (10)",
                                        "18,29,32,36,38 (5)",
                                        "2,11,12,13,15,19,37,39 (8)", 
                                        "6,9,17,20,21,22,23 (7)"),
                      PAM_sidNum = c("7,8,16,28,33,34 (6)",
                                     "1,3,4,5,12,14,24,25,26,27,31,35 (12)",
                                     "32,36,37,38,39 (5)",
                                     "2,11,13,15,18,19 (6)",
                                     "6,9,10,17,20,21,22,23,29,30 (10)"))
cluster  <-  xtable(cluster, caption = "Comparison among different methods when k=5")
align(cluster) <- "clll"
print(cluster, type = 'html', caption.placement = 'top')
```

### <dim id="3b">[Gene clustering](#3a)
In many cases, analysts use cluster analysis to illustrate the results of a differential expression analysis.
#### A smaller dataset
Use different clustering algorithms to cluster the top 972 genes that showed differential expression across the different developmental stage (BH adjusted p value < 10-5).
```{r}
DesMat <- model.matrix(~ devStage, prDes)
Fit <- lmFit(prDat, DesMat)
EbFit <- eBayes(Fit)
topHits <- topTable(EbFit, coef = grep("devStage", colnames(coef(EbFit))), 
                    n = Inf, p.value = 1e-05)
topGenes <- rownames(topHits)
length(topGenes)
topDat <- sprDat[topGenes, ]
```

#### Hierarchical
```{r}
geneC.dis <- dist(topDat, method = 'euclidean')
geneC.hc.a <- hclust(geneC.dis, method = 'average')
plot(geneC.hc.a, labels = FALSE, main = "Hierarchical with Average Linkage", xlab = "")
```

#### Partitioning
```{r, fig.width=9, fig.height=9}
set.seed(1234)
k <- 5
kmeans.genes <- kmeans(topDat, centers = k)

# choose which cluster we want
clusterNum <- 1 

# Set up the axes without plotting; ylim set based on trial run.
par(oma=c(6, 0.5, 0, 0))
plot(kmeans.genes$centers[clusterNum, ], xlim = c(0, 40), ylim = c(-4, 4), type = 'n', 
     frame.plot = TRUE, axes = FALSE, xlab = "", ylab = "Relative expression") 

# Plot the expression of all the genes in the selected cluster in grey. 
matlines(y = t(topDat[kmeans.genes$cluster == clusterNum, ]), col = 'grey') 

# Add the cluster center. This is last so it isn't underneath the members
points(kmeans.genes$centers[clusterNum, ], type = 'l') 

# Optional: colored points to show which development stage the samples are from.
points(kmeans.genes$centers[clusterNum, ],  col = prDes$devStage, pch = 20)

# add x-axis and y-axis
axis(side = 1, at = seq(1, 39, 1), labels = prDes$grp, cex.asis = 0.9, las = 2)
axis(side = 2, at = seq(-4, 4, 2), labels = seq(-4, 4, 2), las = 1)
```

#### Or, probably more commonly used, we can see both dendrograms using heatmaps (through hierarchical clustering): 
```{r}
devStageCols <- brewer.pal(11, "RdGy")[c(2,4,7,9,11)]
heatmap(as.matrix(topDat), col = jGraysFun(256),
        hclustfun = function(x) hclust(x, method = 'average'),
        labCol = prDes$grp, labRow = NA, margin = c(8,1), scale = "none",
        ColSideColor = devStageCols[unclass(prDes$devStage)])
legend("topleft", levels(prDes$devStage), col = devStageCols,
       lty = 1, lwd = 5, cex = 0.5)
```

#### Redefining the attributes
In the previous example, all the samples were used as attributes to cluster genes. However, we can define different attributes, for example, by estimating parameters of a linear model. Consider:
$$
  \begin{equation}
  X_{gi,devStage} = \mu_{g,devStage} + \epsilon_{gi,devStage}
  \end{equation}
$$
Thus, we can define a new attributes for each gene, i.e., $$Att_g=(\mu_{g,E16},\mu_{g,P2},\mu_{g,P6},\mu_{g,P10},\mu_{g,4w})$$ and estimate these parameters.
```{r}
annoTopDat <- stack(as.data.frame(topDat)) # stack probe data tall and skinny
annoTopDat$probeset <- rownames(topDat) # add probeset ID as variable
## get info on gType and devStage, then average over reps within devStage
annoTopDat <- merge(annoTopDat, prDes, by.x = "ind", by.y = "sidChar")
devStageAvg <- ddply(annoTopDat, ~ probeset, function(x) {
  avgByDevStage <- aggregate(values ~ devStage, x, mean)$values
  names(avgByDevStage) <- levels(x$devStage)
  avgByDevStage
  })
## put probset info back into rownames
rownames(devStageAvg) <- devStageAvg$probeset
devStageAvg$probeset <- NULL
str(devStageAvg)
heatmap(as.matrix(devStageAvg), Colv = NA, col = jGraysFun(256),
        hclustfun = function(x) hclust(x,method = 'average'),
        labCol = colnames(devStageAvg), labRow = NA, margin = c(8,1))
```

Look at the average expression of genes within a cluster for each developmental stage.
```{r}
k <- 4
geneDS.km <- kmeans(devStageAvg, centers = k, nstart = 50)
clust.centers <- geneDS.km$centers

#Look at all clusters
op <- par(mfrow = c(2, 2))
for(clusterNum in 1:4) {
  # Set up the axes without plotting; ylim set based on trial run.
  plot(clust.centers[clusterNum,], ylim = c(-4,4), type='n',
       xlab = "Develomental Stage", ylab = "Relative expression",
       axes = F, main = paste("Cluster", clusterNum, sep = " ")) 
  axis(2)
  axis(1, 1:5, c(colnames(clust.centers)[1:4],"4W"), cex.axis = 0.9)
  
  # Plot the expression of all the genes in the selected cluster in grey.
  matlines(y = t(devStageAvg[geneDS.km$cluster == clusterNum, ]),
           col = 'grey') 
  
  # Add the cluster center. This is last so it isn't underneath the members
  points(clust.centers[clusterNum, ] , type = 'l') 
  
  # Optional: points to show development stages.
  points(clust.centers[clusterNum, ],  pch = 20)
  }
par(op)
```


Compare all clusters' centers.
```{r}
plot(clust.centers[clusterNum, ], ylim = c(-4, 4), type = 'n',
     xlab = "Develomental Stage", ylab = "Average expression",
     axes = FALSE, main = "Clusters centers") 
axis(2)
axis(1, 1:5, c(colnames(clust.centers)[1:4],"4W"), cex.axis = 0.9)

for(clusterNum in 1:4) {
  points(clust.centers[clusterNum,], type = 'l', col = clusterNum, lwd=2) 
  points(clust.centers[clusterNum,] , col = clusterNum, pch = 20)
  }
```

We can look at 3-dimensions of the data and illustrate clusters determined by kmeans. The most interesting analysis is to follow with a biological interpretation of the clusters. For that, smaller clusters may be easier to interpret.
```{r}
cloud(devStageAvg[ ,"E16"] ~ devStageAvg[ ,"P6"] * devStageAvg[ ,"4_weeks"], 
      col = geneDS.km$clust, xlab = "E16", ylab = "P6", zlab = "4_weeks")
```

### <dim id="4b">[Statistical measures to evaluate clusters](#4a)
An important issue for clustering is the question of certainty of the cluster membership. Clustering always gives you an answer, even if there aren't really any underlying clusters. There are many ways to address this. Here we introduce an approachable one offered in R, `pvclust`.
```{r}
pvc <- pvclust(topDat, nboot = 100)
plot(pvc, labels = prDes$grp, cex = 0.6)
pvrect(pvc, alpha = 0.95) 
```

### <dim id="5b">[PCA (principal components analysis)](#5a)
In R, we can use `prcomp()` to do PCA. You can also use `svd()`.
```{r}
pcs <- prcomp(sprDat, center = F, scale = F) 

# scree plot
plot(pcs)

# append the rotations for the first 10 PCs to the phenodata
prinComp <- cbind(prDes, pcs$rotation[prDes$sidChar, 1:10]) 

# scatter plot showing us how the first few PCs relate to covariates
plot(prinComp[ ,c("sidNum", "devStage", "gType", "PC1", "PC2", "PC3")],
     pch = 19, cex = 0.8) 

# plot data on first two PCs, colored by development stage
plot(prinComp[ ,c("PC1","PC2")], bg = prDes$devStage, pch = 21, cex = 1.5)
legend(list(x = 0.2, y = 0.3), as.character(levels(prDes$devStage)),
       pch = 21, pt.bg = c(1,2,3,4,5))
```
> This is the end of seminar09.
